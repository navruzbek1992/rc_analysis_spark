{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Reddit Comments Analysis\n",
    "# ### Download and clean data. Estimate polarity scores.\n",
    "\n",
    "# Reddit monthly comments are zipped and available for some modeling.\n",
    "# URL for this is as following https://files.pushshift.io/reddit/comments/.\n",
    "# Since databricks environment is limited to 10GB, only smaller files are downloaded.\n",
    "\n",
    "# First, I download 2011 September comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## nltk is required for sentiment analysis\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## download important libs\n",
    "\n",
    "from pyspark import SparkContext\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import json\n",
    "import bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
       "Out[21]: True</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## this will save zipped file in temp folder\n",
    "!wget 'https://files.pushshift.io/reddit/comments/RC_2011-09.bz2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## import bz2 and unzip the file\n",
    "with bz2.open(\"RC_2011-09.bz2\", \"rb\") as f:\n",
    "    content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## make txt file and write the content\n",
    "f = open(\"RC_comment_09.txt\", \"wb\")\n",
    "f.write(content)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## move files from driver to dbfs file storage\n",
    "## data is moved to databrick's local storage for further processing\n",
    "\n",
    "dbutils.fs.mv(\"file:/databricks/driver/RC_comment_09.txt\", \n",
    "              \"dbfs:/tmp/RC_2011-09.txt\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## create rdd to further work on it\n",
    "rdd = sc.textFile(\"dbfs:/tmp/RC_2011-09.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">[&#39;{&#34;subreddit&#34;:&#34;woahdude&#34;,&#34;subreddit_id&#34;:&#34;t5_2r8tu&#34;,&#34;score_hidden&#34;:false,&#34;edited&#34;:true,&#34;author&#34;:&#34;TheBeardlessSquirrel&#34;,&#34;controversiality&#34;:0,&#34;retrieved_on&#34;:1427543912,&#34;author_flair_text&#34;:null,&#34;name&#34;:&#34;t1_c2gmvge&#34;,&#34;gilded&#34;:0,&#34;link_id&#34;:&#34;t3_k05iw&#34;,&#34;created_utc&#34;:&#34;1314835200&#34;,&#34;author_flair_css_class&#34;:null,&#34;score&#34;:1,&#34;distinguished&#34;:null,&#34;parent_id&#34;:&#34;t3_k05iw&#34;,&#34;downs&#34;:0,&#34;id&#34;:&#34;c2gmvge&#34;,&#34;body&#34;:&#34;At least wait a bit before [reposting](http://www.reddit.com/r/woahdude/comments/jyxly/mighty_morphing_power_art_gif/).&#34;,&#34;ups&#34;:1,&#34;archived&#34;:true}&#39;]\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## data is list of dictionaries\n",
    "print(rdd.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here I start taking a subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## txt file shows that it is txt of json \n",
    "## keep only unix time information and comments\n",
    "## also data that has 'deleted' info has been removed\n",
    "\n",
    "## rdd keys are comment ids give under \"name\"\n",
    "rdd_subset = rdd.map(lambda line : (json.loads(line)['name'],                                    \n",
    "                                    json.loads(line)['author'],\n",
    "                                    json.loads(line)['author_flair_text'],\n",
    "                                    json.loads(line)['created_utc'],\n",
    "                                    json.loads(line)['parent_id'],\n",
    "                                    json.loads(line)['ups'],\n",
    "                                    json.loads(line)['downs'],\n",
    "                                    json.loads(line)['retrieved_on'],\n",
    "                                    json.loads(line)['subreddit'],\n",
    "                                    json.loads(line)['body'],)\n",
    "                    ).filter(lambda line: line if '[deleted]' not in line[9] else None)\n",
    "\n",
    "df = spark.createDataFrame(rdd_subset).toDF(\"name\",\"author\",\n",
    "                                                       \"author_flair_text\",\n",
    "                                                       \"unix_time\",\"parent_id\",\n",
    "                                                       \"ups\",\"downs\",\"retrieved_on\",\n",
    "                                                       \"subreddit\", \"comment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## first i loop through comments and find average len of words in every comment\n",
    "rdd_commments = rdd_subset.map(lambda line: line[-1])\n",
    "rdd_commments.cache()\n",
    "\n",
    "rdd_comments_ave_len_words = rdd_commments.map(lambda line: \n",
    "                  sum([len(part) for part in line.split(' ')]) / len(line.split(' ')) \n",
    "                 )\n",
    "\n",
    "\n",
    "ave_string_mean = rdd_comments_ave_len_words.mean()\n",
    "ave_string_std = rdd_comments_ave_len_words.sampleStdev()\n",
    "\n",
    "## second i loop through comments and find longest len of words\n",
    "## this will help to know the len of long strings and then I remove \n",
    "## long strings that do not have any semantic value\n",
    "## such as urls etc.\n",
    "rdd_comments_longest_len_words = rdd_commments.map(lambda line: \n",
    "                  max( \n",
    "                    [len(part) for part in line.split(' ')]\n",
    "                  ))\n",
    "long_string_mean = rdd_comments_longest_len_words.mean()\n",
    "long_string_std = rdd_comments_longest_len_words.sampleStdev()\n",
    "\n",
    "## third loop through and see if comments just keep only numbers or just None\n",
    "rdd_comments_none = rdd_commments.map(lambda line: True if type(line) is type(None) else False)\n",
    "rdd_comments_int = rdd_commments.map(lambda line: True if type(line) is type(int()) else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[22]: 5.500056123492271</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## average string len \n",
    "## this looks a little bit longer than 4.7 char\n",
    "## as explained in this link below, English words on average has 4.7 char\n",
    "## http://norvig.com/mayzner.html\n",
    "## so I will remove very long strings \n",
    "ave_string_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[27]: 13.457259730113545</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ave_string_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[91]: 14.468464958205868</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Long strings are too long so their average as well\n",
    "## i use this 14 as a cutoff length to trim tokens later on in short_words function below\n",
    "long_string_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[44]: 26.213877524345452</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "long_string_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[73]: False</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## all values are false\n",
    "## so there is no comment that is only int\n",
    "any(rdd_comments_int.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[69]: False</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## all values are false\n",
    "## so there is no comment that is only None\n",
    "any(rdd_comments_none.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+----------+--------------------+-----------------+----------+---------+---+-----+------------+---------+--------------------+\n",
       "      name|              author|author_flair_text| unix_time|parent_id|ups|downs|retrieved_on|subreddit|             comment|\n",
       "+----------+--------------------+-----------------+----------+---------+---+-----+------------+---------+--------------------+\n",
       "t1_c2gmvge|TheBeardlessSquirrel|             null|1314835200| t3_k05iw|  1|    0|  1427543912| woahdude|At least wait a b...|\n",
       "+----------+--------------------+-----------------+----------+---------+---+-----+------------+---------+--------------------+\n",
       "only showing top 1 row\n",
       "\n",
       "None\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## now i go back to df and start shortening and tokenizing comments\n",
    "## subset looks fine\n",
    "## it has unix time, comments and all other info that is needed\n",
    "print(df.show(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## here I create several functions for processing\n",
    "  \n",
    "from pyspark.sql.types import ArrayType, StringType, FloatType, IntegerType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def remove_int(x):\n",
    "    return [a for a in x if a.isdigit() is False]\n",
    "\n",
    "def short_words(x):\n",
    "    return [a for a in x if len(a) <= 14]\n",
    "    \n",
    "def join_tokens(x):\n",
    "    return [\" \".join(x)]\n",
    "  \n",
    "def sentiment_score(x):\n",
    "    vs = analyzer.polarity_scores(x[0])\n",
    "    return vs['neg'], vs['neu'], vs['pos'], vs['compound']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "regtokenizer = RegexTokenizer(inputCol='comment', outputCol='comment_tokens', toLowercase = False)\n",
    "df_regtokened = regtokenizer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "remove_int_udf = udf(lambda line: remove_int(line), ArrayType(StringType()))\n",
    "shorten_words_udf = udf(lambda line: short_words(line), ArrayType(StringType()))\n",
    "join_tokens_udf = udf(lambda line: join_tokens(line), ArrayType(StringType()))\n",
    "sentiment_score_udf = udf(lambda line: sentiment_score(line), ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_tokened = df_regtokened.withColumn('comment_tokens_cleaned', remove_int_udf(\"comment_tokens\"))\n",
    "\n",
    "df_tokened = df_tokened.withColumn('comment_tokens_cleaned', shorten_words_udf(\"comment_tokens_cleaned\"))\n",
    "df_tokened = df_tokened.withColumn('comment_tokens_joined', join_tokens_udf(\"comment_tokens_cleaned\"))\n",
    "\n",
    "df_tokened = df_tokened.withColumn('comment_sentiment', sentiment_score_udf(\"comment_tokens_joined\"))\n",
    "df_tokened = df_tokened.withColumn('sentiment_neg', df_tokened.comment_sentiment[0]\n",
    "                                  ).withColumn('sentiment_neu', df_tokened.comment_sentiment[1]\n",
    "                                  ).withColumn('sentiment_pos', df_tokened.comment_sentiment[2]\n",
    "                                  ).withColumn('sentiment_com', df_tokened.comment_sentiment[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+-----------------------------+-------------+-------------+-------------+-------------+\n",
       "comment_sentiment            |sentiment_neg|sentiment_neu|sentiment_pos|sentiment_com|\n",
       "+-----------------------------+-------------+-------------+-------------+-------------+\n",
       "[0.0, 1.0, 0.0, 0.0]         |0.0          |1.0          |0.0          |0.0          |\n",
       "[0.0, 1.0, 0.0, 0.0]         |0.0          |1.0          |0.0          |0.0          |\n",
       "[0.093, 0.809, 0.098, 0.0516]|0.093        |0.809        |0.098        |0.0516       |\n",
       "[0.0, 1.0, 0.0, 0.0]         |0.0          |1.0          |0.0          |0.0          |\n",
       "[0.0, 1.0, 0.0, 0.0]         |0.0          |1.0          |0.0          |0.0          |\n",
       "[0.0, 0.649, 0.351, 0.6597]  |0.0          |0.649        |0.351        |0.6597       |\n",
       "[0.0, 0.672, 0.328, 0.9442]  |0.0          |0.672        |0.328        |0.9442       |\n",
       "[0.0, 1.0, 0.0, 0.0]         |0.0          |1.0          |0.0          |0.0          |\n",
       "[0.084, 0.805, 0.111, 0.1779]|0.084        |0.805        |0.111        |0.1779       |\n",
       "[0.0, 0.915, 0.085, 0.0772]  |0.0          |0.915        |0.085        |0.0772       |\n",
       "+-----------------------------+-------------+-------------+-------------+-------------+\n",
       "only showing top 10 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_tokened.select('comment_sentiment', 'sentiment_neg', 'sentiment_neu','sentiment_pos', 'sentiment_com').show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "def find_average_len_words(line):\n",
    "    return sum([len(part) for part in line.split(' ')]) / len(line.split(' '))\n",
    "  \n",
    "find_average_len_words_udf = udf(lambda line: find_average_len_words(line[0]), FloatType())\n",
    "\n",
    "df_tokened_check = df_tokened.withColumn('comment_tokens_mean', find_average_len_words_udf(\"comment_tokens_joined\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+------------------------+--------------------------------+\n",
       "avg(comment_tokens_mean)|stddev_samp(comment_tokens_mean)|\n",
       "+------------------------+--------------------------------+\n",
       "        4.52885701992511|              1.0821986118738078|\n",
       "+------------------------+--------------------------------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean, stddev, col\n",
    "\n",
    "df_tokened_check.select(mean(col('comment_tokens_mean')), stddev(col('comment_tokens_mean'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now that avg comment token is close to 4.7\n",
    "## http://norvig.com/mayzner.html\n",
    "\n",
    "## also stdev is reduced considerebly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# VADER relies on several key words in the sentence\n",
    "# removing them would alter the polarity scores\n",
    "# - conjuctions (no stopword removal)\n",
    "# - degree modifiers (no lemmatizing)\n",
    "# - capitalization (no lowercasing)\n",
    "# - punctuation (no punctuation removal)\n",
    "\n",
    "# Still I will have functions for each case that could be used later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here I do a simple check.\n",
    "# To see how urls in the string will effect scores.\n",
    "# Urls and long strings wont effect. They will be removed to keep our data in smaller size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">{&#39;neg&#39;: 0.368, &#39;neu&#39;: 0.632, &#39;pos&#39;: 0.0, &#39;compound&#39;: -0.5423}\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(analyzer.polarity_scores(\"at Least wait a bit before bad [reposting]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">{&#39;neg&#39;: 0.414, &#39;neu&#39;: 0.586, &#39;pos&#39;: 0.0, &#39;compound&#39;: -0.6408}\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(analyzer.polarity_scores(\"at least wait a bit before bad [reposting](http://www.reddit.com/r/woahdude/comments/jyxly/mighty_morphing_power_art_gif/).\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I check how numbers alter polarity scores.\n",
    "# Numbers affect our scores. But numbers are not useful since they have no semantic value. They will be removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">{&#39;neg&#39;: 0.368, &#39;neu&#39;: 0.632, &#39;pos&#39;: 0.0, &#39;compound&#39;: -0.5423}\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(analyzer.polarity_scores(\"at least wait a bit before bad [reposting]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">{&#39;neg&#39;: 0.333, &#39;neu&#39;: 0.667, &#39;pos&#39;: 0.0, &#39;compound&#39;: -0.5423}\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(analyzer.polarity_scores(\"at Least wait a bit before bad [reposting] 123\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So only removed \n",
    "# - very long words\n",
    "# - numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data in rdd are just rows.\n",
    "# Each function that is applied on rdd goes through each row.\n",
    "# In rdd line[0] is unix time and line[1] is comments in string.\n",
    "# Functions are applied by lambda and only uses line[1] since it contains comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ## tokenize for sentences\n",
    "# ## rdd rows are given in the tuple\n",
    "# ## rdd_subset contains comments in the last part of the tuple\n",
    "# ## so I return all elements until the last one and modify the last element which is reddit comment\n",
    "# sent_rdd = rdd_subset.map(lambda line: (line[:9], \n",
    "#                                         tokenize_sent(line[9])))\n",
    "\n",
    "# ## tokenize for words\n",
    "# ## now sent_rdd is changed and each row is tuple of tuple and list together\n",
    "# ## tuple's second element is list which is modified comments\n",
    "# ## tuple's first element is tuple of line[:9] from the first step\n",
    "# word_rdd = sent_rdd.map(lambda line: (line[0], \n",
    "#                                       tokenize_word(line[1])))\n",
    "\n",
    "# ## remove int\n",
    "# removed_int_rdd = word_rdd.map(lambda line: (line[0], \n",
    "#                                              remove_int(line[1])))\n",
    "\n",
    "# ## remove long tokens\n",
    "# shortened_rdd = removed_int_rdd.map(lambda line: (line[0], \n",
    "#                                                   short_words(line[1])))\n",
    "\n",
    "# ## join cleaned tokens for sentiment analysis\n",
    "# joined_rdd = shortened_rdd.map(lambda line: (line[0], \n",
    "#                                              join_tokens(line[1])))\n",
    "\n",
    "# ## sentiments are added as well \n",
    "# sentiment_rdd = joined_rdd.map(lambda line: (line[0], line[1], \n",
    "#                                              sentiment_score(line[1])))\n",
    "\n",
    "# ## sentiment scores are wrapped in tuples\n",
    "# ## so now each row is tuple + list + tuple\n",
    "# ## here i open last tuple\n",
    "# rdd_processed = sentiment_rdd.map(lambda line: (line[0], line[1][0], \n",
    "#                                                 line[2][0], line[2][1], \n",
    "#                                                 line[2][2], line[2][3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ## here I just open nested tuples for each row/line tuple \n",
    "# rdd_processed_ = rdd_processed.map(lambda line: (line[0][0], line[0][1], line[0][2],\n",
    "#                                                  line[0][3], line[0][4], line[0][5],\n",
    "#                                                  line[0][6], line[0][7], line[0][8], \n",
    "#                                                  line[1], line[2], line[3], line[4], line[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">[(&#39;t1_c2gmvge&#39;, &#39;TheBeardlessSquirrel&#39;, None, &#39;1314835200&#39;, &#39;t3_k05iw&#39;, 1, 0, 1427543912, &#39;woahdude&#39;, &#39;At least wait a bit before&#39;, 0.0, 1.0, 0.0, 0.0)]\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ## now our data is as following, just list\n",
    "# print(rdd_processed_.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ## here I create a dataframe from rdd and give column names\n",
    "# df_subset = spark.createDataFrame(rdd_processed_).toDF(\"name\",\"author\",\n",
    "#                                                        \"author_flair_text\",\n",
    "#                                                        \"unix_time\",\"parent_id\",\n",
    "#                                                        \"ups\",\"downs\",\"retrieved_on\",\n",
    "#                                                        \"subreddit\", \"comment\", \"neg\", \n",
    "#                                                        \"neu\", \"pos\", \"com\")\n",
    "# # print(df_subset.show(1, truncate=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display(df_subset.show(1, truncate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## save the df\n",
    "df_subset.write.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").save(\"dbfs:/FileStore/tmp/df_09_subset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/FileStore/tmp/df_09_subset.csv/</td><td>df_09_subset.csv/</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## check if the data is saved\n",
    "## it will be used by another notebook \n",
    "%fs ls dbfs:/FileStore/tmp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "name": "2.2 Working with Text Files",
  "notebookId": 1977860122152764
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
